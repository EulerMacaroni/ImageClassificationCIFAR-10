{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Architecture and Training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wbT7eWWVhYQc",
        "outputId": "578960e9-aafe-450c-c701-db210b588ce0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),  #\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
        "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.3, 3.3), value='random')\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "])\n",
        "\n",
        "# **Load CIFAR-10 dataset**\n",
        "batch_size = 128\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# **Training-Validation Split**\n",
        "train_size = int(0.9 * len(trainset))  # 90% Train, 10% Validation\n",
        "val_size = len(trainset) - train_size\n",
        "train_subset, val_subset = random_split(trainset, [train_size, val_size])\n",
        "\n",
        "trainloader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "valloader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AdvancedCNN(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.2):\n",
        "        super(AdvancedCNN, self).__init__()\n",
        "\n",
        "        # First Conv Block\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Second Conv Block (Added Extra Layer)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv3_extra = nn.Conv2d(128, 128, kernel_size=3, padding=1)  # Extra Layer\n",
        "        self.bn3_extra = nn.BatchNorm2d(128)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Third Conv Block (Added Extra Layer)\n",
        "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(256)\n",
        "        self.conv5_extra = nn.Conv2d(256, 256, kernel_size=3, padding=1)  # Extra Layer\n",
        "        self.bn5_extra = nn.BatchNorm2d(256)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
        "        self.bn_fc1 = nn.BatchNorm1d(512)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool1(F.relu(self.bn2(self.conv2(x))))\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn3_extra(self.conv3_extra(x)))  # Extra Layer\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "        x = F.relu(self.bn5_extra(self.conv5_extra(x)))  # Extra Layer\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = x.view(-1, 256 * 4 * 4)\n",
        "        x = F.relu(self.bn_fc1(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model = AdvancedCNN().to(device)\n",
        "print(model)\n",
        "\n",
        "# **Loss Function, Optimizer & Learning Rate Scheduler**\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=75)\n",
        "\n",
        "\n",
        "# Training\n",
        "def train_model(model, optimizer, scheduler, num_epochs=75, patience=5):\n",
        "    best_val_loss = float(\"inf\")\n",
        "    counter = 0  # Early stopping counter\n",
        "    train_losses, val_losses, train_acc, val_acc = [], [], [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        correct, total, running_loss = 0, 0, 0.0\n",
        "\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_losses.append(running_loss / len(trainloader))\n",
        "        train_acc.append(100 * correct / total)\n",
        "\n",
        "        # **Validation Step**\n",
        "        model.eval()\n",
        "        correct, total, val_loss = 0, 0, 0.0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in valloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_losses.append(val_loss / len(valloader))\n",
        "        val_acc.append(100 * correct / total)\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_acc[-1]:.2f}%, Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_acc[-1]:.2f}%\")\n",
        "\n",
        "        # **Early Stopping Logic**\n",
        "        if val_losses[-1] < best_val_loss:\n",
        "            best_val_loss = val_losses[-1]\n",
        "            counter = 0\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")  # Save the best model\n",
        "        else:\n",
        "            counter += 1\n",
        "            if counter >= patience:\n",
        "                print(f\" Early stopping triggered at epoch {epoch+1}.\")\n",
        "                break  # Stop training\n",
        "\n",
        "    return train_losses, train_acc, val_losses, val_acc\n",
        "\n",
        "\n",
        "# **Train the Model & Get Metrics**\n",
        "train_losses, train_acc, val_losses, val_acc = train_model(model, optimizer, scheduler)\n",
        "\n",
        "# **Load Best Model Before Testing**\n",
        "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "\n",
        "# **Test Accuracy Evaluation**\n",
        "correct, total = 0, 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f\" Final Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "# **Plot Training & Validation Curves**\n",
        "def plot_metrics(train_losses, val_losses, train_acc, val_acc):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    # **Loss Plot**\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Validation Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    # **Accuracy Plot**\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_acc, label=\"Train Accuracy\")\n",
        "    plt.plot(epochs, val_acc, label=\"Validation Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.title(\"Training & Validation Accuracy\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# **Generate Plots**\n",
        "plot_metrics(train_losses, val_losses, train_acc, val_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Image Class: bird\n",
            "Model Predicted Class: airplane\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Define CIFAR-10 classes\n",
        "cifar10_classes = [\n",
        "    \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \n",
        "    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "]\n",
        "\n",
        "model = AdvancedCNN()  # Instantiate the model\n",
        "model.load_state_dict(torch.load(\"state_of_the_art.pth\", map_location=torch.device('cpu')))  # Load weights\n",
        "model.eval()  # Set to evaluation mode\n",
        "# Generate an image using OpenAI's API (DALL·E)\n",
        "from openai import OpenAI\n",
        "\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "# Choose a random class\n",
        "import random\n",
        "chosen_class = random.choice(cifar10_classes)\n",
        "\n",
        "# Generate an image using DALL·E\n",
        "\n",
        "response = client.images.generate(\n",
        "    model=\"dall-e-3\",\n",
        "    # prompt=\"a white siamese cat\",\n",
        "    prompt=f\"An abstract, surreal, and visually ambiguous 32x32 pixel image inspired by CIFAR-10 classes. The image should contain overlapping features from multiple CIFAR-10 categories, such as a bird perched on a truck, or a cat blending into an airplane silhouette. The style should be distorted, blurred, or in an unusual artistic style that makes classification non-trivial.\",\n",
        "    size=\"1024x1024\",\n",
        "    quality=\"standard\",\n",
        "    n=1,\n",
        ")\n",
        "\n",
        "\n",
        "image_url = response.data[0].url\n",
        "image = Image.open(BytesIO(requests.get(image_url).content))\n",
        "\n",
        "# Preprocess the image (resize, normalize)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Resize to CIFAR-10 size\n",
        "    transforms.ToTensor(),  # Convert to tensor\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])  # CIFAR-10 normalization\n",
        "])\n",
        "\n",
        "input_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Predict using the model\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)\n",
        "    predicted_class_idx = output.argmax(dim=1).item()\n",
        "    predicted_class = cifar10_classes[predicted_class_idx]\n",
        "\n",
        "# Show Results\n",
        "print(f\"Generated Image Class: {chosen_class}\")\n",
        "print(f\"Model Predicted Class: {predicted_class}\")\n",
        "\n",
        "# Display the generated image\n",
        "image.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
